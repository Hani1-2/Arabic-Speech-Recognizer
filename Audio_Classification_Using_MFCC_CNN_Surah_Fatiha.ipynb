{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/Hani1-2/DeepLearningAssignmnt/blob/master/Audio_Classification_Using_MFCC_CNN_Surah_Fatiha.ipynb",
      "authorship_tag": "ABX9TyPdFNWDekKFA2XGxk7AwQJ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hani1-2/Arabic-Speech-Recognizer/blob/main/Audio_Classification_Using_MFCC_CNN_Surah_Fatiha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "OamN8IBktMWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "# path to json file that stores MFCCs and genre labels for each processed segment\n",
        "DATA_PATH = \"/content/drive/MyDrive/surah_fatiha/data_surah_1.json\"\n",
        "\n",
        "def load_data(data_path):\n",
        "    \"\"\"Loads training dataset from json file.\n",
        "        :param data_path (str): Path to json file containing data\n",
        "        :return X (ndarray): Inputs\n",
        "        :return y (ndarray): Targets\n",
        "    \"\"\"\n",
        "\n",
        "    with open(data_path, \"r\") as fp:\n",
        "        data = json.load(fp)\n",
        "\n",
        "    # convert lists to numpy arrays\n",
        "    X = np.array(data[\"mfcc\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "\n",
        "    print(\"Data succesfully loaded!\")\n",
        "\n",
        "    return  X, y\n"
      ],
      "metadata": {
        "id": "1unMn2N0tQoC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot History"
      ],
      "metadata": {
        "id": "VwHjSamytRI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n",
        "        :param history: Training history of model\n",
        "        :return:\n",
        "    \"\"\"\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "\n",
        "    # create accuracy sublpot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
        "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy eval\")\n",
        "\n",
        "    # create error sublpot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
        "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
        "    axs[1].set_ylabel(\"Error\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Error eval\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oKL4Uj0gtU9I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dataset"
      ],
      "metadata": {
        "id": "tOyNPDr89Etk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_datasets(test_size, validation_size):\n",
        "    \"\"\"Loads data and splits it into train, validation and test sets.\n",
        "    :param test_size (float): Value in [0, 1] indicating percentage of data set to allocate to test split\n",
        "    :param validation_size (float): Value in [0, 1] indicating percentage of train set to allocate to validation split\n",
        "    :return X_train (ndarray): Input training set\n",
        "    :return X_validation (ndarray): Input validation set\n",
        "    :return X_test (ndarray): Input test set\n",
        "    :return y_train (ndarray): Target training set\n",
        "    :return y_validation (ndarray): Target validation set\n",
        "    :return y_test (ndarray): Target test set\n",
        "    \"\"\"\n",
        "\n",
        "    # load data\n",
        "    X, y = load_data(DATA_PATH)\n",
        "\n",
        "    # create train, validation and test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
        "\n",
        "    # add an axis to input sets\n",
        "    X_train = X_train[..., np.newaxis]\n",
        "    X_validation = X_validation[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "\n",
        "    return X_train, X_validation, X_test, y_train, y_validation, y_test\n"
      ],
      "metadata": {
        "id": "I98RRteJ3kCt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model"
      ],
      "metadata": {
        "id": "9T6b2ia29OGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape):\n",
        "    \"\"\"Generates CNN model\n",
        "    :param input_shape (tuple): Shape of input set\n",
        "    :return model: CNN model\n",
        "    \"\"\"\n",
        "\n",
        "    # build network topology\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # 1st conv layer\n",
        "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "    # 2nd conv layer\n",
        "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "    # # 3rd conv layer\n",
        "    # model.add(keras.layers.Conv2D(128, (2, 2), activation='relu'))\n",
        "    # model.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
        "    # model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "    # flatten output and feed it into dense layer\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.2))\n",
        "\n",
        "    # output layer\n",
        "    model.add(keras.layers.Dense(28, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "D4mdf_k36O_V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, X, y):\n",
        "    \"\"\"Predict a single sample using the trained model\n",
        "    :param model: Trained classifier\n",
        "    :param X: Input data\n",
        "    :param y (int): Target\n",
        "    \"\"\"\n",
        "\n",
        "    # add a dimension to input data for sample - model.predict() expects a 4d array in this case\n",
        "    X = X[np.newaxis, ...] # array shape (1, 130, 13, 1)\n",
        "\n",
        "    # perform prediction\n",
        "    prediction = model.predict(X)\n",
        "\n",
        "    # get index with max value\n",
        "    predicted_index = np.argmax(prediction, axis=1)\n",
        "\n",
        "    print(\"Target: {}, Predicted label: {}\".format(y, predicted_index))\n"
      ],
      "metadata": {
        "id": "XvcSJBv59S7z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # get train, validation, test splits\n",
        "    X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.2)\n",
        "    # create network\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "    model = build_model(input_shape)\n",
        "\n",
        "    # compile model\n",
        "    optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimiser,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=100)\n",
        "\n",
        "    # plot accuracy/error for training and validation\n",
        "    plot_history(history)\n",
        "\n",
        "    # evaluate model on test set\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "    print('\\nTest accuracy:', test_acc)\n",
        "\n",
        "    # pick a sample to predict from the test set\n",
        "    X_to_predict = X_test[100]\n",
        "    y_to_predict = y_test[100]\n",
        "\n",
        "    # predict sample\n",
        "    predict(model, X_to_predict, y_to_predict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SFPlVTH-9Vce",
        "outputId": "1c858297-f42a-4b4d-e1f8-48e08f5da98b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data succesfully loaded!\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 7, 11, 32)         320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 4, 6, 32)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 4, 6, 32)         128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 2, 4, 64)          18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 1, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 1, 2, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 28)                7196      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59,420\n",
            "Trainable params: 59,228\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "2102/2102 [==============================] - 15s 6ms/step - loss: 2.7052 - accuracy: 0.1944 - val_loss: 2.2834 - val_accuracy: 0.3079\n",
            "Epoch 2/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 2.1812 - accuracy: 0.3237 - val_loss: 1.9222 - val_accuracy: 0.4162\n",
            "Epoch 3/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 1.8910 - accuracy: 0.4041 - val_loss: 1.6702 - val_accuracy: 0.4846\n",
            "Epoch 4/100\n",
            "2102/2102 [==============================] - 10s 5ms/step - loss: 1.6877 - accuracy: 0.4603 - val_loss: 1.4906 - val_accuracy: 0.5380\n",
            "Epoch 5/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 1.5359 - accuracy: 0.5064 - val_loss: 1.3469 - val_accuracy: 0.5848\n",
            "Epoch 6/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 1.4069 - accuracy: 0.5398 - val_loss: 1.2233 - val_accuracy: 0.6282\n",
            "Epoch 7/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 1.2996 - accuracy: 0.5781 - val_loss: 1.1200 - val_accuracy: 0.6556\n",
            "Epoch 8/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 1.2103 - accuracy: 0.6043 - val_loss: 1.0373 - val_accuracy: 0.6822\n",
            "Epoch 9/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 1.1271 - accuracy: 0.6333 - val_loss: 0.9593 - val_accuracy: 0.7086\n",
            "Epoch 10/100\n",
            "2102/2102 [==============================] - 10s 5ms/step - loss: 1.0654 - accuracy: 0.6518 - val_loss: 0.8954 - val_accuracy: 0.7305\n",
            "Epoch 11/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 1.0029 - accuracy: 0.6716 - val_loss: 0.8466 - val_accuracy: 0.7471\n",
            "Epoch 12/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.9510 - accuracy: 0.6879 - val_loss: 0.7867 - val_accuracy: 0.7655\n",
            "Epoch 13/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.8977 - accuracy: 0.7069 - val_loss: 0.7472 - val_accuracy: 0.7754\n",
            "Epoch 14/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.8572 - accuracy: 0.7208 - val_loss: 0.7044 - val_accuracy: 0.7869\n",
            "Epoch 15/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.8158 - accuracy: 0.7333 - val_loss: 0.6711 - val_accuracy: 0.7985\n",
            "Epoch 16/100\n",
            "2102/2102 [==============================] - 10s 5ms/step - loss: 0.7826 - accuracy: 0.7422 - val_loss: 0.6369 - val_accuracy: 0.8086\n",
            "Epoch 17/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.7510 - accuracy: 0.7532 - val_loss: 0.6013 - val_accuracy: 0.8222\n",
            "Epoch 18/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.7144 - accuracy: 0.7656 - val_loss: 0.5656 - val_accuracy: 0.8342\n",
            "Epoch 19/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.6886 - accuracy: 0.7748 - val_loss: 0.5400 - val_accuracy: 0.8406\n",
            "Epoch 20/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.6685 - accuracy: 0.7806 - val_loss: 0.5190 - val_accuracy: 0.8467\n",
            "Epoch 21/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.6463 - accuracy: 0.7866 - val_loss: 0.5041 - val_accuracy: 0.8495\n",
            "Epoch 22/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.6183 - accuracy: 0.7972 - val_loss: 0.4946 - val_accuracy: 0.8506\n",
            "Epoch 23/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.5999 - accuracy: 0.8030 - val_loss: 0.4660 - val_accuracy: 0.8634\n",
            "Epoch 24/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.5856 - accuracy: 0.8084 - val_loss: 0.4474 - val_accuracy: 0.8691\n",
            "Epoch 25/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.5646 - accuracy: 0.8157 - val_loss: 0.4370 - val_accuracy: 0.8728\n",
            "Epoch 26/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.5479 - accuracy: 0.8179 - val_loss: 0.4264 - val_accuracy: 0.8737\n",
            "Epoch 27/100\n",
            "2102/2102 [==============================] - 10s 5ms/step - loss: 0.5310 - accuracy: 0.8234 - val_loss: 0.4038 - val_accuracy: 0.8828\n",
            "Epoch 28/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.5197 - accuracy: 0.8289 - val_loss: 0.3872 - val_accuracy: 0.8894\n",
            "Epoch 29/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.5025 - accuracy: 0.8352 - val_loss: 0.3673 - val_accuracy: 0.8959\n",
            "Epoch 30/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.4904 - accuracy: 0.8380 - val_loss: 0.3635 - val_accuracy: 0.8948\n",
            "Epoch 31/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.4775 - accuracy: 0.8437 - val_loss: 0.3511 - val_accuracy: 0.8982\n",
            "Epoch 32/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.4681 - accuracy: 0.8460 - val_loss: 0.3322 - val_accuracy: 0.9061\n",
            "Epoch 33/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.4568 - accuracy: 0.8497 - val_loss: 0.3446 - val_accuracy: 0.8988\n",
            "Epoch 34/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.4452 - accuracy: 0.8511 - val_loss: 0.3164 - val_accuracy: 0.9091\n",
            "Epoch 35/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.4357 - accuracy: 0.8562 - val_loss: 0.3206 - val_accuracy: 0.9077\n",
            "Epoch 36/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.4247 - accuracy: 0.8605 - val_loss: 0.3042 - val_accuracy: 0.9145\n",
            "Epoch 37/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.4183 - accuracy: 0.8620 - val_loss: 0.3065 - val_accuracy: 0.9099\n",
            "Epoch 38/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.4102 - accuracy: 0.8627 - val_loss: 0.2944 - val_accuracy: 0.9169\n",
            "Epoch 39/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.4018 - accuracy: 0.8669 - val_loss: 0.2914 - val_accuracy: 0.9163\n",
            "Epoch 40/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.3929 - accuracy: 0.8699 - val_loss: 0.2889 - val_accuracy: 0.9162\n",
            "Epoch 41/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.3837 - accuracy: 0.8740 - val_loss: 0.2855 - val_accuracy: 0.9166\n",
            "Epoch 42/100\n",
            "2102/2102 [==============================] - 12s 5ms/step - loss: 0.3772 - accuracy: 0.8744 - val_loss: 0.2651 - val_accuracy: 0.9227\n",
            "Epoch 43/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.3712 - accuracy: 0.8764 - val_loss: 0.2610 - val_accuracy: 0.9242\n",
            "Epoch 44/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.3660 - accuracy: 0.8779 - val_loss: 0.2561 - val_accuracy: 0.9261\n",
            "Epoch 45/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.3623 - accuracy: 0.8793 - val_loss: 0.2649 - val_accuracy: 0.9226\n",
            "Epoch 46/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.3542 - accuracy: 0.8823 - val_loss: 0.2537 - val_accuracy: 0.9255\n",
            "Epoch 47/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.3483 - accuracy: 0.8844 - val_loss: 0.2498 - val_accuracy: 0.9264\n",
            "Epoch 48/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.3442 - accuracy: 0.8843 - val_loss: 0.2435 - val_accuracy: 0.9289\n",
            "Epoch 49/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.3415 - accuracy: 0.8857 - val_loss: 0.2441 - val_accuracy: 0.9275\n",
            "Epoch 50/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.3326 - accuracy: 0.8882 - val_loss: 0.2370 - val_accuracy: 0.9318\n",
            "Epoch 51/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.3252 - accuracy: 0.8903 - val_loss: 0.2220 - val_accuracy: 0.9365\n",
            "Epoch 52/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.3212 - accuracy: 0.8923 - val_loss: 0.2365 - val_accuracy: 0.9305\n",
            "Epoch 53/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.3178 - accuracy: 0.8936 - val_loss: 0.2202 - val_accuracy: 0.9363\n",
            "Epoch 54/100\n",
            "2102/2102 [==============================] - 12s 5ms/step - loss: 0.3144 - accuracy: 0.8946 - val_loss: 0.2265 - val_accuracy: 0.9349\n",
            "Epoch 55/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.3132 - accuracy: 0.8951 - val_loss: 0.2101 - val_accuracy: 0.9390\n",
            "Epoch 56/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.3049 - accuracy: 0.8983 - val_loss: 0.2115 - val_accuracy: 0.9393\n",
            "Epoch 57/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.2998 - accuracy: 0.9001 - val_loss: 0.2161 - val_accuracy: 0.9365\n",
            "Epoch 58/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2998 - accuracy: 0.9004 - val_loss: 0.2199 - val_accuracy: 0.9362\n",
            "Epoch 59/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2952 - accuracy: 0.9019 - val_loss: 0.2023 - val_accuracy: 0.9419\n",
            "Epoch 60/100\n",
            "2102/2102 [==============================] - 12s 5ms/step - loss: 0.2890 - accuracy: 0.9036 - val_loss: 0.2002 - val_accuracy: 0.9412\n",
            "Epoch 61/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2850 - accuracy: 0.9043 - val_loss: 0.1986 - val_accuracy: 0.9421\n",
            "Epoch 62/100\n",
            "2102/2102 [==============================] - 12s 5ms/step - loss: 0.2859 - accuracy: 0.9038 - val_loss: 0.1949 - val_accuracy: 0.9459\n",
            "Epoch 63/100\n",
            "2102/2102 [==============================] - 13s 6ms/step - loss: 0.2807 - accuracy: 0.9065 - val_loss: 0.1904 - val_accuracy: 0.9442\n",
            "Epoch 64/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.2746 - accuracy: 0.9086 - val_loss: 0.1888 - val_accuracy: 0.9463\n",
            "Epoch 65/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.2744 - accuracy: 0.9079 - val_loss: 0.1885 - val_accuracy: 0.9461\n",
            "Epoch 66/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2694 - accuracy: 0.9092 - val_loss: 0.1832 - val_accuracy: 0.9490\n",
            "Epoch 67/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2673 - accuracy: 0.9106 - val_loss: 0.1874 - val_accuracy: 0.9462\n",
            "Epoch 68/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2645 - accuracy: 0.9124 - val_loss: 0.1813 - val_accuracy: 0.9466\n",
            "Epoch 69/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2617 - accuracy: 0.9120 - val_loss: 0.1738 - val_accuracy: 0.9485\n",
            "Epoch 70/100\n",
            "2102/2102 [==============================] - 13s 6ms/step - loss: 0.2601 - accuracy: 0.9133 - val_loss: 0.1729 - val_accuracy: 0.9500\n",
            "Epoch 71/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.2583 - accuracy: 0.9130 - val_loss: 0.1758 - val_accuracy: 0.9499\n",
            "Epoch 72/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.2573 - accuracy: 0.9130 - val_loss: 0.1706 - val_accuracy: 0.9513\n",
            "Epoch 73/100\n",
            "2102/2102 [==============================] - 10s 5ms/step - loss: 0.2486 - accuracy: 0.9168 - val_loss: 0.1755 - val_accuracy: 0.9486\n",
            "Epoch 74/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2493 - accuracy: 0.9169 - val_loss: 0.1667 - val_accuracy: 0.9525\n",
            "Epoch 75/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2465 - accuracy: 0.9183 - val_loss: 0.1640 - val_accuracy: 0.9531\n",
            "Epoch 76/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2461 - accuracy: 0.9165 - val_loss: 0.1705 - val_accuracy: 0.9487\n",
            "Epoch 77/100\n",
            "2102/2102 [==============================] - 13s 6ms/step - loss: 0.2434 - accuracy: 0.9188 - val_loss: 0.1662 - val_accuracy: 0.9504\n",
            "Epoch 78/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.2388 - accuracy: 0.9196 - val_loss: 0.1668 - val_accuracy: 0.9504\n",
            "Epoch 79/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2417 - accuracy: 0.9185 - val_loss: 0.1650 - val_accuracy: 0.9512\n",
            "Epoch 80/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2367 - accuracy: 0.9203 - val_loss: 0.1624 - val_accuracy: 0.9533\n",
            "Epoch 81/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2344 - accuracy: 0.9205 - val_loss: 0.1618 - val_accuracy: 0.9514\n",
            "Epoch 82/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2323 - accuracy: 0.9214 - val_loss: 0.1613 - val_accuracy: 0.9527\n",
            "Epoch 83/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2323 - accuracy: 0.9213 - val_loss: 0.1582 - val_accuracy: 0.9537\n",
            "Epoch 84/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.2296 - accuracy: 0.9226 - val_loss: 0.1519 - val_accuracy: 0.9569\n",
            "Epoch 85/100\n",
            "2102/2102 [==============================] - 12s 5ms/step - loss: 0.2251 - accuracy: 0.9254 - val_loss: 0.1513 - val_accuracy: 0.9559\n",
            "Epoch 86/100\n",
            "2102/2102 [==============================] - 10s 5ms/step - loss: 0.2221 - accuracy: 0.9251 - val_loss: 0.1520 - val_accuracy: 0.9553\n",
            "Epoch 87/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2237 - accuracy: 0.9238 - val_loss: 0.1516 - val_accuracy: 0.9547\n",
            "Epoch 88/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2192 - accuracy: 0.9269 - val_loss: 0.1498 - val_accuracy: 0.9559\n",
            "Epoch 89/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2207 - accuracy: 0.9255 - val_loss: 0.1496 - val_accuracy: 0.9568\n",
            "Epoch 90/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2174 - accuracy: 0.9265 - val_loss: 0.1546 - val_accuracy: 0.9542\n",
            "Epoch 91/100\n",
            "2102/2102 [==============================] - 12s 6ms/step - loss: 0.2153 - accuracy: 0.9263 - val_loss: 0.1498 - val_accuracy: 0.9555\n",
            "Epoch 92/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2134 - accuracy: 0.9271 - val_loss: 0.1454 - val_accuracy: 0.9577\n",
            "Epoch 93/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2108 - accuracy: 0.9280 - val_loss: 0.1494 - val_accuracy: 0.9556\n",
            "Epoch 94/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2137 - accuracy: 0.9275 - val_loss: 0.1448 - val_accuracy: 0.9576\n",
            "Epoch 95/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2110 - accuracy: 0.9287 - val_loss: 0.1423 - val_accuracy: 0.9586\n",
            "Epoch 96/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2073 - accuracy: 0.9310 - val_loss: 0.1389 - val_accuracy: 0.9600\n",
            "Epoch 97/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2084 - accuracy: 0.9286 - val_loss: 0.1411 - val_accuracy: 0.9591\n",
            "Epoch 98/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2033 - accuracy: 0.9319 - val_loss: 0.1438 - val_accuracy: 0.9569\n",
            "Epoch 99/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2065 - accuracy: 0.9296 - val_loss: 0.1415 - val_accuracy: 0.9592\n",
            "Epoch 100/100\n",
            "2102/2102 [==============================] - 11s 5ms/step - loss: 0.2053 - accuracy: 0.9299 - val_loss: 0.1451 - val_accuracy: 0.9567\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "876/876 - 2s - loss: 0.1462 - accuracy: 0.9573 - 2s/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4f00e318b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test accuracy: 0.9573177099227905\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "Target: 1, Predicted label: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SAVED_MODEL_PATH = \"model.h5\"\n",
        "model.save(SAVED_MODEL_PATH)\n"
      ],
      "metadata": {
        "id": "BTD9uMSvNR9a"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "OV5zC4cn9apU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz_KerExDf6h",
        "outputId": "1ea0b41e-74b9-473d-84eb-a874fe1fcc4c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_mapping = {\n",
        "    1:\"Bis'mi\",\n",
        "    2:\"Al-lahi\",\n",
        "    3:\"Al-rahmaani\",\n",
        "    4:\"Al-raheemi\",\n",
        "    5:\"Alhamdu\",\n",
        "    6:\"lillaahi\",\n",
        "    7:\"Rabbil\",\n",
        "    8:\"aalameen\",\n",
        "    9:\"Ar-Rahmaan\",\n",
        "    10:\"Ar-Raheem\",\n",
        "    11:\"Maaliki\",\n",
        "    12:\"Yumid\",\n",
        "    13:\"Diin\",\n",
        "    14:\"Iyyaka\",\n",
        "    15:\"Na'abudu\",\n",
        "    16:\"Iyyaka\",\n",
        "    17:\"Nasta'een\",\n",
        "    18:\"Ihdinas\",\n",
        "    19:\"Siraatal\",\n",
        "    20:\"Mustaqeem\",\n",
        "    21:\"Siraatal\",\n",
        "    22:\"Ladheena\",\n",
        "    23:\"An'amta\",\n",
        "    24:\"Alaihim\",\n",
        "    25:\"Ghayril\",\n",
        "    26:\"Maghdubi\",\n",
        "    27:\"Alaihim\",\n",
        "    28:\"Wala al-dalina\"}"
      ],
      "metadata": {
        "id": "FfMiG8AIm7Zp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_RATE = 22050\n",
        "TRACK_DURATION = 2 # measured in seconds\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
        "file = '/content/003.wav'\n",
        "\n",
        "def save_mfcc(file_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n",
        "    mfcc_lst = []\n",
        "    # we divide the track into 5 segments\n",
        "    # to calculate sample per segment - we need to know the number of samples per track (which is the sample rate * the track duration )\n",
        "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
        "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
        "\n",
        "    signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "    # process all segments of audio file\n",
        "    for d in range(num_segments):\n",
        "\n",
        "        # calculate start and finish sample for current segment\n",
        "        start = samples_per_segment * d\n",
        "        finish = start + samples_per_segment\n",
        "\n",
        "        # extract mfcc - for each segment of signal\n",
        "        mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "        mfcc = mfcc.T\n",
        "\n",
        "        # store only mfcc feature with expected number of vectors\n",
        "        if len(mfcc) == num_mfcc_vectors_per_segment:\n",
        "            mfcc_lst.append(mfcc.tolist())\n",
        "    return mfcc_lst"
      ],
      "metadata": {
        "id": "Be0D-fewPUFg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa==0.9.2"
      ],
      "metadata": {
        "id": "aUqQBLldslyj",
        "outputId": "2ef2333d-af70-4c45-9876-7d86bf03007b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa==0.9.2 in /usr/local/lib/python3.9/dist-packages (0.9.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9.2) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9.2) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9.2) (1.10.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9.2) (1.1.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9.2) (3.0.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9.2) (0.4.2)\n",
            "Requirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9.2) (0.56.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9.2) (23.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9.2) (1.6.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9.2) (0.12.1)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.9/dist-packages (from librosa==0.9.2) (4.4.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.45.1->librosa==0.9.2) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.45.1->librosa==0.9.2) (67.6.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.0->librosa==0.9.2) (2.27.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.0->librosa==0.9.2) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->librosa==0.9.2) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from soundfile>=0.10.2->librosa==0.9.2) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.2) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sMG45e0unpC2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "SAVED_MODEL_PATH = \"model.h5\"\n",
        "SAMPLE_RATE = 22050\n",
        "TRACK_DURATION = 2 # measured in seconds\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
        "\n",
        "class _Keyword_Spotting_Service:\n",
        "    \"\"\"Singleton class for keyword spotting inference with trained models.\n",
        "\n",
        "    :param model: Trained model\n",
        "    \"\"\"\n",
        "    \n",
        "    model = None\n",
        "    _mapping = [\n",
        "    \"Bis'mi\",\n",
        "    \"Al-lahi\",\n",
        "    \"Al-rahmaani\",\n",
        "    \"Al-raheemi\",\n",
        "    \"Alhamdu\",\n",
        "    \"lillaahi\",\n",
        "    \"Rabbil\",\n",
        "    \"aalameen\",\n",
        "    \"Ar-Rahmaan\",\n",
        "    \"Ar-Raheem\",\n",
        "    \"Maaliki\",\n",
        "    \"Yumid\",\n",
        "    \"Diin\",\n",
        "    \"Iyyaka\",\n",
        "    \"Na'abudu\",\n",
        "    \"Iyyaka\",\n",
        "    \"Nasta'een\",\n",
        "    \"Ihdinas\",\n",
        "    \"Siraatal\",\n",
        "    \"Mustaqeem\",\n",
        "    \"Siraatal\",\n",
        "    \"Ladheena\",\n",
        "    \"An'amta\",\n",
        "    \"Alaihim\",\n",
        "    \"Ghayril\",\n",
        "    \"Maghdubi\",\n",
        "    \"Alaihim\",\n",
        "    \"Wala al-dalina\"\n",
        "    ]\n",
        "    _instance = None\n",
        "\n",
        "    # generate predictions and confidence scores\n",
        "    # def predict_with_confidence(model, x):\n",
        "    #     # generate predictions and confidence scores for each input\n",
        "    #     preds = model.predict(x)\n",
        "    #     confs = int(np.max(preds, axis=-1))\n",
        "    #     return preds, confs\n",
        "\n",
        "    def predict(self, file_path):\n",
        "        \"\"\"\n",
        "\n",
        "        :param file_path (str): Path to audio file to predict\n",
        "        :return predicted_keyword (str): Keyword predicted by the model\n",
        "        \"\"\"\n",
        "\n",
        "        # extract MFCC\n",
        "        # MFCCs = np.array([[-183.87974548339844, 131.75009155273438, 2.2060155868530273, -8.105782508850098, -38.07963562011719, 17.40044403076172, -0.6676614284515381, -22.161405563354492, -10.295568466186523, 6.563896179199219, -3.6954336166381836, -11.445362091064453, 9.491683959960938], [-180.80616760253906, 115.36853790283203, -2.8926031589508057, -9.07729721069336, -52.492637634277344, 26.909496307373047, -2.7331502437591553, -14.425968170166016, -19.478710174560547, 5.680357933044434, -1.7577323913574219, -16.35490608215332, 13.524815559387207], [-192.94027709960938, 91.42437744140625, -23.93356704711914, -23.16407012939453, -60.30923843383789, 32.025535583496094, 10.04941177368164, 0.4003942012786865, -24.948360443115234, 5.307590007781982, 1.5026012659072876, -26.008087158203125, 17.219728469848633], [-175.62313842773438, 101.17229461669922, -32.41350555419922, -30.539745330810547, -64.07801055908203, 31.093017578125, 12.911539077758789, 7.282844543457031, -30.573162078857422, 7.644656658172607, 4.2728986740112305, -30.014530181884766, 20.74167251586914], [-166.6313018798828, 105.19999694824219, -35.174930572509766, -30.445606231689453, -63.564903259277344, 27.228313446044922, 14.329790115356445, 15.870038986206055, -33.5143928527832, 8.455541610717773, 7.194486618041992, -29.158828735351562, 15.765297889709473], [-166.1154327392578, 110.21952819824219, -37.62902069091797, -28.95749282836914, -62.26484298706055, 23.820415496826172, 12.333368301391602, 15.781059265136719, -34.20686340332031, 4.830765247344971, 7.3923163414001465, -27.21042251586914, 9.298351287841797], [-166.02870178222656, \n",
        "# 121.54912567138672, -45.28936004638672, -26.586345672607422, -62.76194763183594, 27.857032775878906, 8.119768142700195, 10.21646785736084, -32.60343933105469, 4.115324020385742, 6.260907173156738, -25.593948364257812, 0.23342549800872803], [-163.90133666992188, 121.15217590332031, -41.218467712402344, -18.846481323242188, -57.43403625488281, 29.522968292236328, 0.46502673625946045, 4.530104160308838, -26.924739837646484, 5.935633659362793, 5.122352600097656, -17.716205596923828, -5.116012096405029], [-134.5664825439453, 154.80996704101562, -31.109590530395508, -16.877721786499023, -54.75687789916992, 26.409751892089844, -11.305870056152344, -2.671182632446289, -19.20587921142578, 8.538867950439453, 4.430681228637695, -13.631662368774414, -4.969356060028076]])\n",
        "        MFCCs = np.array(self.preprocess(file_path))\n",
        "        \n",
        "        # we need a 4-dim array to feed to the model for prediction: (# samples, # time steps, # coefficients, 1)\n",
        "        MFCCs = MFCCs[np.newaxis, ..., np.newaxis]\n",
        "\n",
        "        # get the predicted label\n",
        "        predictions = self.model.predict(MFCCs) # a 2d array [[]]\n",
        "        predicted_index = np.argmax(predictions)\n",
        "        # index return the index which has highest score\n",
        "        confs = tf.nn.softmax(predictions)\n",
        "        # Get corresponding probability value for predicted class\n",
        "        confidence_score = predictions[0][predicted_index]\n",
        "        predicted_keyword = self._mapping[predicted_index]\n",
        "        # print('prediction',predicted_index,predicted_keyword)\n",
        "        return predicted_keyword, confidence_score\n",
        "\n",
        "\n",
        "    def preprocess(self, file_path, num_mfcc=13, n_fft=2048, hop_length=512,num_segments=10):\n",
        "        mfcc_lst = []\n",
        "        # we divide the track into 5 segments\n",
        "        # to calculate sample per segment - we need to know the number of samples per track (which is the sample rate * the track duration )\n",
        "        samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
        "        num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
        "\n",
        "        signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "        # process all segments of audio file\n",
        "        for d in range(num_segments):\n",
        "\n",
        "            # calculate start and finish sample for current segment\n",
        "            start = samples_per_segment * d\n",
        "            finish = start + samples_per_segment\n",
        "\n",
        "            # extract mfcc - for each segment of signal\n",
        "            mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "            mfcc = mfcc.T\n",
        "\n",
        "            # store only mfcc feature with expected number of vectors\n",
        "            if len(mfcc) == num_mfcc_vectors_per_segment:\n",
        "                mfcc_lst.append(mfcc.tolist())\n",
        "        return mfcc_lst[0]\n",
        "\n",
        "\n",
        "def Keyword_Spotting_Service():\n",
        "    \"\"\"Factory function for Keyword_Spotting_Service class.\n",
        "\n",
        "    :return _Keyword_Spotting_Service._instance (_Keyword_Spotting_Service):\n",
        "    \"\"\"\n",
        "\n",
        "    # ensure an instance is created only the first time the factory function is called\n",
        "    if _Keyword_Spotting_Service._instance is None:\n",
        "        _Keyword_Spotting_Service._instance = _Keyword_Spotting_Service()\n",
        "        _Keyword_Spotting_Service.model = tf.keras.models.load_model(SAVED_MODEL_PATH)\n",
        "    return _Keyword_Spotting_Service._instance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # create 2 instances of the keyword spotting service\n",
        "    kss = Keyword_Spotting_Service()\n",
        "    kss1 = Keyword_Spotting_Service()\n",
        "\n",
        "    # check that different instances of the keyword spotting service point back to the same object (singleton)\n",
        "    assert kss is kss1\n",
        "\n",
        "    # make a prediction\n",
        "    keyword, condfidence_score = kss.predict(\"002.wav\")\n",
        "    print(keyword)\n",
        "    print('Confidence',condfidence_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9U0v9aqn0HH",
        "outputId": "f56627b8-cc3b-4a41-a5ff-c44c02e6d38c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-9804f04c18e4>:100: FutureWarning: Pass y=[0.02628682 0.03317782 0.03789439 ... 0.06536973 0.06302683 0.05670235], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
            "<ipython-input-27-9804f04c18e4>:100: FutureWarning: Pass y=[0.05048585 0.05129176 0.05542339 ... 0.05260923 0.03931705 0.02578977], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
            "<ipython-input-27-9804f04c18e4>:100: FutureWarning: Pass y=[0.01763017 0.01292829 0.00694799 ... 0.16284892 0.16833648 0.17078859], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
            "<ipython-input-27-9804f04c18e4>:100: FutureWarning: Pass y=[ 0.17023386  0.1445559   0.11728735 ... -0.247976   -0.21162751\n",
            " -0.17117757], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
            "<ipython-input-27-9804f04c18e4>:100: FutureWarning: Pass y=[-0.15783417 -0.15813784 -0.19044383 ... -0.19742785 -0.14594273\n",
            "  0.        ], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
            "<ipython-input-27-9804f04c18e4>:100: FutureWarning: Pass y=[], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 165ms/step\n",
            "lillaahi\n",
            "Confidence 0.99961436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## try to Split audio and to predict each word"
      ],
      "metadata": {
        "id": "SgczfLOKN0lU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio = ['test3.wav']\n",
        "Ayah = []\n",
        "for f in audio:\n",
        "  # create 2 instances of the keyword spotting service\n",
        "    kss = Keyword_Spotting_Service()\n",
        "    kss1 = Keyword_Spotting_Service()\n",
        "\n",
        "    # check that different instances of the keyword spotting service point back to the same object (singleton)\n",
        "    assert kss is kss1\n",
        "\n",
        "    # make a prediction\n",
        "    keyword, condfidence_score = kss.predict(f)\n",
        "    print(keyword)\n",
        "    \n",
        "    print('Confidence',condfidence_score)\n",
        "    if condfidence_score >.7:\n",
        "      Ayah.append(keyword)\n"
      ],
      "metadata": {
        "id": "-B19MgJooI3F",
        "outputId": "c9abb0f0-7ffc-48ab-adfa-dedb15788d32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n",
            "Na'abudu\n",
            "Confidence 0.58477926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-9804f04c18e4>:100: FutureWarning: Pass y=[-0.00873394 -0.01433475 -0.01386717 ... -0.01177989 -0.00525943\n",
            "  0.00422414], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
            "<ipython-input-27-9804f04c18e4>:100: FutureWarning: Pass y=[0.01262137 0.0186716  0.02377728 ... 0.06622896 0.06485698 0.06262731], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
            "<ipython-input-27-9804f04c18e4>:100: FutureWarning: Pass y=[ 0.05842116  0.05321707  0.04928912 ... -0.09084725 -0.0872895\n",
            " -0.09458985], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
            "<ipython-input-27-9804f04c18e4>:100: FutureWarning: Pass y=[-0.10580225 -0.11466143 -0.12125018 ... -0.06296474 -0.08495137\n",
            " -0.10425947], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
            "<ipython-input-27-9804f04c18e4>:100: FutureWarning: Pass y=[-0.12308238 -0.14151621 -0.15630935 ...  0.01831005  0.03976179\n",
            "  0.05070899], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
            "<ipython-input-27-9804f04c18e4>:100: FutureWarning: Pass y=[ 0.05983699  0.07013817  0.0764285  ... -0.04274204 -0.03529769\n",
            " -0.0214678 ], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
            "<ipython-input-27-9804f04c18e4>:100: FutureWarning: Pass y=[-3.4357023e-03  1.5586036e-02  3.3769887e-02 ... -2.4227328e-03\n",
            " -5.5027878e-05  1.9539287e-03], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
            "<ipython-input-27-9804f04c18e4>:100: FutureWarning: Pass y=[ 0.00502215  0.00864099  0.01223374 ... -0.06448279 -0.0578417\n",
            " -0.04984703], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
            "<ipython-input-27-9804f04c18e4>:100: FutureWarning: Pass y=[-0.04033626 -0.03036539 -0.02266889 ... -0.00803005 -0.01020391\n",
            " -0.01354833], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
            "<ipython-input-27-9804f04c18e4>:100: FutureWarning: Pass y=[-0.01690747 -0.01816054 -0.01648924 ...  0.03463819  0.03723989\n",
            "  0.02302227], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ayah"
      ],
      "metadata": {
        "id": "M86ow0HKPtWJ",
        "outputId": "e6da79ab-b05b-4ac1-ec95-e458a04afb70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bnm2dP2oQKOp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}