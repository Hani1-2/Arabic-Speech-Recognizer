{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tpkOgeuJO7kqbEy1d8hyl_1Ag_rB2XQI",
      "authorship_tag": "ABX9TyOAGZggapKZGjbcRcM1q16p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hani1-2/Arabic-Speech-Recognizer/blob/main/ANN_arabic_speech_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2qJNKrQRgBdi"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "data_path = '/content/drive/MyDrive/FYP-Code/data_prep_ann.json'\n",
        "with open(data_path, \"r\") as fp:\n",
        "      data = json.load(fp)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "j9GxcnCegyH3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Split the dataset into independent and dependent dataset\n",
        "X=np.array(data['MFCCs'])\n",
        "y=np.array(data['labels'])"
      ],
      "metadata": {
        "id": "BL5mZgo6gYR1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx2p9OOfmGGE",
        "outputId": "3f62e566-9dcd-4ba1-f884-9b142c136cdd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21952, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAB-FIxCmlbh",
        "outputId": "fa2510bf-df34-49b0-db92-85035afe1a32"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21952,)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Label Encoding\n",
        "###y=np.array(pd.get_dummies(y))\n",
        "### Label Encoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder=LabelEncoder()\n",
        "y=to_categorical(labelencoder.fit_transform(y))"
      ],
      "metadata": {
        "id": "yMil2AZsmNip"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RLSR_8FmP4s",
        "outputId": "7369850f-68bf-4ae2-9cfd-1b971ffa42d9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21952, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "jGRQ3yd2gz0Q"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4PUuufvg8rL",
        "outputId": "c7bd27ef-6a5b-4c08-e1cc-475c79902086"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17561, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyQJYSHLhAUd",
        "outputId": "98cec1f3-25af-4df1-8814-97f3a32a3f5c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17561, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "3RRywx02hJof"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "from PIL import Image\n",
        "import pathlib\n",
        "from keras import layers\n",
        "from keras import layers\n",
        "import keras"
      ],
      "metadata": {
        "id": "rTRS2PVsjK37"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(28, activation='softmax'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "aew9_8l2hWN7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1epOckoYhaEX",
        "outputId": "75cb43c5-32b1-4a0a-cc68-5d7ae8015abd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 256)               10496     \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 28)                1820      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 53,468\n",
            "Trainable params: 53,468\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Trianing my model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime \n",
        "\n",
        "num_epochs = 40\n",
        "num_batch_size = 32\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='audio_classification.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXq05kRZhm4D",
        "outputId": "7f260165-a357-4a0d-b429-aa01404a755d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "547/549 [============================>.] - ETA: 0s - loss: 0.0462 - accuracy: 0.9861\n",
            "Epoch 1: val_loss improved from inf to 0.10486, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0461 - accuracy: 0.9861 - val_loss: 0.1049 - val_accuracy: 0.9697\n",
            "Epoch 2/40\n",
            "537/549 [============================>.] - ETA: 0s - loss: 0.0643 - accuracy: 0.9780\n",
            "Epoch 2: val_loss improved from 0.10486 to 0.08582, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0657 - accuracy: 0.9776 - val_loss: 0.0858 - val_accuracy: 0.9722\n",
            "Epoch 3/40\n",
            "540/549 [============================>.] - ETA: 0s - loss: 0.0984 - accuracy: 0.9686\n",
            "Epoch 3: val_loss did not improve from 0.08582\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0973 - accuracy: 0.9689 - val_loss: 0.1047 - val_accuracy: 0.9702\n",
            "Epoch 4/40\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9842\n",
            "Epoch 4: val_loss improved from 0.08582 to 0.06806, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 3s 6ms/step - loss: 0.0494 - accuracy: 0.9842 - val_loss: 0.0681 - val_accuracy: 0.9768\n",
            "Epoch 5/40\n",
            "542/549 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.9831\n",
            "Epoch 5: val_loss did not improve from 0.06806\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0521 - accuracy: 0.9830 - val_loss: 0.0916 - val_accuracy: 0.9738\n",
            "Epoch 6/40\n",
            "539/549 [============================>.] - ETA: 0s - loss: 0.0791 - accuracy: 0.9744\n",
            "Epoch 6: val_loss did not improve from 0.06806\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0787 - accuracy: 0.9745 - val_loss: 0.1313 - val_accuracy: 0.9663\n",
            "Epoch 7/40\n",
            "533/549 [============================>.] - ETA: 0s - loss: 0.0594 - accuracy: 0.9825\n",
            "Epoch 7: val_loss did not improve from 0.06806\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0601 - accuracy: 0.9824 - val_loss: 0.1850 - val_accuracy: 0.9586\n",
            "Epoch 8/40\n",
            "539/549 [============================>.] - ETA: 0s - loss: 0.0887 - accuracy: 0.9750\n",
            "Epoch 8: val_loss did not improve from 0.06806\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0888 - accuracy: 0.9749 - val_loss: 0.1472 - val_accuracy: 0.9581\n",
            "Epoch 9/40\n",
            "544/549 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9922\n",
            "Epoch 9: val_loss improved from 0.06806 to 0.03053, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.0305 - val_accuracy: 0.9941\n",
            "Epoch 10/40\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9821\n",
            "Epoch 10: val_loss did not improve from 0.03053\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0609 - accuracy: 0.9821 - val_loss: 0.0922 - val_accuracy: 0.9772\n",
            "Epoch 11/40\n",
            "543/549 [============================>.] - ETA: 0s - loss: 0.0649 - accuracy: 0.9803\n",
            "Epoch 11: val_loss did not improve from 0.03053\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0646 - accuracy: 0.9805 - val_loss: 0.0916 - val_accuracy: 0.9736\n",
            "Epoch 12/40\n",
            "536/549 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9885\n",
            "Epoch 12: val_loss did not improve from 0.03053\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0406 - accuracy: 0.9883 - val_loss: 0.1688 - val_accuracy: 0.9556\n",
            "Epoch 13/40\n",
            "535/549 [============================>.] - ETA: 0s - loss: 0.0651 - accuracy: 0.9802\n",
            "Epoch 13: val_loss did not improve from 0.03053\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0660 - accuracy: 0.9798 - val_loss: 0.1124 - val_accuracy: 0.9661\n",
            "Epoch 14/40\n",
            "548/549 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9888\n",
            "Epoch 14: val_loss did not improve from 0.03053\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0388 - accuracy: 0.9888 - val_loss: 0.0371 - val_accuracy: 0.9918\n",
            "Epoch 15/40\n",
            "542/549 [============================>.] - ETA: 0s - loss: 0.0661 - accuracy: 0.9817\n",
            "Epoch 15: val_loss did not improve from 0.03053\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0667 - accuracy: 0.9817 - val_loss: 0.0471 - val_accuracy: 0.9870\n",
            "Epoch 16/40\n",
            "542/549 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.9897\n",
            "Epoch 16: val_loss did not improve from 0.03053\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0368 - accuracy: 0.9898 - val_loss: 0.0634 - val_accuracy: 0.9834\n",
            "Epoch 17/40\n",
            "543/549 [============================>.] - ETA: 0s - loss: 0.0510 - accuracy: 0.9853\n",
            "Epoch 17: val_loss did not improve from 0.03053\n",
            "549/549 [==============================] - 3s 6ms/step - loss: 0.0506 - accuracy: 0.9854 - val_loss: 0.0675 - val_accuracy: 0.9806\n",
            "Epoch 18/40\n",
            "538/549 [============================>.] - ETA: 0s - loss: 0.0572 - accuracy: 0.9840\n",
            "Epoch 18: val_loss did not improve from 0.03053\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0564 - accuracy: 0.9841 - val_loss: 0.0377 - val_accuracy: 0.9913\n",
            "Epoch 19/40\n",
            "541/549 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.9875\n",
            "Epoch 19: val_loss did not improve from 0.03053\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0423 - accuracy: 0.9875 - val_loss: 0.0546 - val_accuracy: 0.9829\n",
            "Epoch 20/40\n",
            "541/549 [============================>.] - ETA: 0s - loss: 0.0726 - accuracy: 0.9793\n",
            "Epoch 20: val_loss did not improve from 0.03053\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0717 - accuracy: 0.9796 - val_loss: 0.0437 - val_accuracy: 0.9893\n",
            "Epoch 21/40\n",
            "540/549 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9910\n",
            "Epoch 21: val_loss did not improve from 0.03053\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.0807 - val_accuracy: 0.9749\n",
            "Epoch 22/40\n",
            "546/549 [============================>.] - ETA: 0s - loss: 0.0544 - accuracy: 0.9848\n",
            "Epoch 22: val_loss did not improve from 0.03053\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0542 - accuracy: 0.9849 - val_loss: 0.0337 - val_accuracy: 0.9918\n",
            "Epoch 23/40\n",
            "548/549 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9959\n",
            "Epoch 23: val_loss improved from 0.03053 to 0.01487, saving model to audio_classification.hdf5\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.0149 - val_accuracy: 0.9952\n",
            "Epoch 24/40\n",
            "547/549 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9873\n",
            "Epoch 24: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0524 - accuracy: 0.9871 - val_loss: 0.2698 - val_accuracy: 0.9312\n",
            "Epoch 25/40\n",
            "536/549 [============================>.] - ETA: 0s - loss: 0.0709 - accuracy: 0.9812\n",
            "Epoch 25: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0695 - accuracy: 0.9816 - val_loss: 0.0478 - val_accuracy: 0.9870\n",
            "Epoch 26/40\n",
            "542/549 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9945\n",
            "Epoch 26: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0471 - val_accuracy: 0.9888\n",
            "Epoch 27/40\n",
            "548/549 [============================>.] - ETA: 0s - loss: 0.0531 - accuracy: 0.9861\n",
            "Epoch 27: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0530 - accuracy: 0.9862 - val_loss: 0.0233 - val_accuracy: 0.9927\n",
            "Epoch 28/40\n",
            "541/549 [============================>.] - ETA: 0s - loss: 0.0619 - accuracy: 0.9845\n",
            "Epoch 28: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0611 - accuracy: 0.9847 - val_loss: 0.0667 - val_accuracy: 0.9843\n",
            "Epoch 29/40\n",
            "546/549 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9915\n",
            "Epoch 29: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0292 - accuracy: 0.9915 - val_loss: 0.0715 - val_accuracy: 0.9804\n",
            "Epoch 30/40\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9912\n",
            "Epoch 30: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 3s 6ms/step - loss: 0.0363 - accuracy: 0.9912 - val_loss: 0.0838 - val_accuracy: 0.9786\n",
            "Epoch 31/40\n",
            "545/549 [============================>.] - ETA: 0s - loss: 0.0676 - accuracy: 0.9827\n",
            "Epoch 31: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0674 - accuracy: 0.9828 - val_loss: 0.0665 - val_accuracy: 0.9852\n",
            "Epoch 32/40\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9922\n",
            "Epoch 32: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0259 - accuracy: 0.9922 - val_loss: 0.0851 - val_accuracy: 0.9806\n",
            "Epoch 33/40\n",
            "533/549 [============================>.] - ETA: 0s - loss: 0.0472 - accuracy: 0.9865\n",
            "Epoch 33: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0462 - accuracy: 0.9867 - val_loss: 0.0456 - val_accuracy: 0.9870\n",
            "Epoch 34/40\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9886\n",
            "Epoch 34: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0439 - accuracy: 0.9886 - val_loss: 0.0562 - val_accuracy: 0.9882\n",
            "Epoch 35/40\n",
            "541/549 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9967\n",
            "Epoch 35: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.0708 - val_accuracy: 0.9845\n",
            "Epoch 36/40\n",
            "549/549 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9878\n",
            "Epoch 36: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 3s 6ms/step - loss: 0.0504 - accuracy: 0.9878 - val_loss: 0.1233 - val_accuracy: 0.9690\n",
            "Epoch 37/40\n",
            "543/549 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 0.9852\n",
            "Epoch 37: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0608 - accuracy: 0.9852 - val_loss: 0.0430 - val_accuracy: 0.9902\n",
            "Epoch 38/40\n",
            "537/549 [============================>.] - ETA: 0s - loss: 0.0396 - accuracy: 0.9894\n",
            "Epoch 38: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0404 - accuracy: 0.9891 - val_loss: 0.0891 - val_accuracy: 0.9772\n",
            "Epoch 39/40\n",
            "545/549 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9876\n",
            "Epoch 39: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 2s 4ms/step - loss: 0.0530 - accuracy: 0.9877 - val_loss: 0.0547 - val_accuracy: 0.9900\n",
            "Epoch 40/40\n",
            "536/549 [============================>.] - ETA: 0s - loss: 0.0360 - accuracy: 0.9908\n",
            "Epoch 40: val_loss did not improve from 0.01487\n",
            "549/549 [==============================] - 2s 3ms/step - loss: 0.0354 - accuracy: 0.9909 - val_loss: 0.0774 - val_accuracy: 0.9838\n",
            "Training completed in time:  0:02:22.045689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename=\"007.wav\"\n",
        "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
        "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "\n",
        "print(mfccs_scaled_features)\n",
        "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "print(mfccs_scaled_features)\n",
        "print(mfccs_scaled_features.shape)\n",
        "predicted_label=model.predict(mfccs_scaled_features)\n",
        "print(predicted_label)\n",
        "# prediction_class = labelencoder.inverse_transform(predicted_label) \n",
        "# prediction_class\n",
        "y_classes = np.argmax(predicted_label, axis=-1)\n",
        "print(y_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2nGySBGnJD_",
        "outputId": "6437a04b-18af-489a-92ca-4c1b2a1b5a53"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-196.17476     186.60579     -43.693718     -2.95328     -22.635359\n",
            "   -1.6014059     5.051543     14.187795    -20.004782      4.884835\n",
            "   -3.197479    -11.130185     -0.4112453    -8.425037      7.6617155\n",
            "  -21.629713     -2.4375868    -8.845539     -3.4667387    -0.76815015\n",
            "  -13.189546      6.372229    -14.55708       1.0147884    -4.0114837\n",
            "  -10.856888     -2.2666636    -7.5505314    -4.776728     -8.244527\n",
            "   -1.9299394    -5.496899     -4.0487366    -3.146125      1.968653\n",
            "    3.094914      7.056366     16.88408      14.446403     18.89331   ]\n",
            "[[-196.17476     186.60579     -43.693718     -2.95328     -22.635359\n",
            "    -1.6014059     5.051543     14.187795    -20.004782      4.884835\n",
            "    -3.197479    -11.130185     -0.4112453    -8.425037      7.6617155\n",
            "   -21.629713     -2.4375868    -8.845539     -3.4667387    -0.76815015\n",
            "   -13.189546      6.372229    -14.55708       1.0147884    -4.0114837\n",
            "   -10.856888     -2.2666636    -7.5505314    -4.776728     -8.244527\n",
            "    -1.9299394    -5.496899     -4.0487366    -3.146125      1.968653\n",
            "     3.094914      7.056366     16.88408      14.446403     18.89331   ]]\n",
            "(1, 40)\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "[[0.0000000e+00 1.1421369e-36 1.3630567e-09 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 2.5668249e-36 0.0000000e+00 1.0000000e+00 3.0683383e-29\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.5937115e-24\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 5.6483625e-29 0.0000000e+00\n",
            "  1.3324622e-24 0.0000000e+00 2.2926283e-33 0.0000000e+00 0.0000000e+00\n",
            "  1.7350373e-38 0.0000000e+00 0.0000000e+00]]\n",
            "[8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['mapping'][8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ibpJRHtioL_q",
        "outputId": "1365ce10-e114-459c-a346-cefc85a8d677"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ar-Rahmaan'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zz3UrNcrpCMD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}